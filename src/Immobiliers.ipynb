{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bfe288edf75fcab",
   "metadata": {},
   "source": [
    "# Install required libraries\n",
    "To install the required libraries from the requirements file, use the following command:\n",
    "\"pip install -r requirements.txt\"\n",
    "\n",
    "# Directed by:\n",
    "- Kevin: 0, 1, 2, 3, 4, 8.4, 8.5\n",
    "- Gabriel: 3, 4, 5, 6, 7, 8.1, 8.2, 8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53642eda9ec2b9a",
   "metadata": {},
   "source": [
    "# 0. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd  # Library for data manipulation and analysis, often used for handling tabular data\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt  # Module for data visualization through plots and charts\n",
    "import seaborn as sns  # Data visualization library built on Matplotlib, offering advanced plotting functions and attractive visual styles\n",
    "import matplotlib.ticker as ticker  # Module for customizing axis tick labels and formatting in Matplotlib plots\n",
    "\n",
    "# Regression Models for Predicting Continuous Values\n",
    "from sklearn.tree import DecisionTreeRegressor  # Decision Tree model for regression tasks\n",
    "from sklearn.metrics import mean_absolute_error, r2_score  # Metrics for evaluating model performance\n",
    "from sklearn.ensemble import RandomForestRegressor  # Random Forest model for regression, an ensemble of decision trees\n",
    "from sklearn.model_selection import GridSearchCV  # Tool for hyperparameter tuning using grid search and cross-validation\n",
    "\n",
    "# Data Processing and Splitting\n",
    "from sklearn.model_selection import train_test_split  # Function to split data into training and test sets\n",
    "\n",
    "# Suppress warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings to keep the output clean"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8e7ee4e4c7bc577a",
   "metadata": {},
   "source": "# 1. Collect the data"
  },
  {
   "cell_type": "code",
   "id": "85551d7dbe9fb0a6",
   "metadata": {},
   "source": [
    "# Load the dataset from the specified path\n",
    "data = pd.read_csv(\"../data/G3_immobiliers.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cbf45a371c705860",
   "metadata": {},
   "source": "# 2. Data cleaning and preparation"
  },
  {
   "cell_type": "code",
   "id": "66be6389cb011278",
   "metadata": {},
   "source": [
    "# Display the first 10 rows of the dataset to understand its structure\n",
    "data.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1337ba17f41d05c7",
   "metadata": {},
   "source": [
    "# Display dataset information including column names, data types, and missing values\n",
    "data.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca484119e4f3beda",
   "metadata": {},
   "source": [
    "# Get statistical summaries of numerical columns\n",
    "data.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a5c993b7adf5ad4f",
   "metadata": {},
   "source": [
    "# Check the total number of missing values in each column\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "221b46483afa7508",
   "metadata": {},
   "source": [
    "# Drop unnecessary columns that are not useful for predictive modeling\n",
    "df_data = data[[\"valeur_fonciere\", \"date_mutation\",\n",
    "    \"code_postal\", \"code_commune\", \"nom_commune\", \"code_departement\",\n",
    "    \"type_local\", \"surface_reelle_bati\", \"nombre_pieces_principales\",\n",
    "    \"surface_terrain\", \"nature_culture\"\n",
    "]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "12a3aa7aa381f636",
   "metadata": {},
   "source": [
    "# Convert \"valeur_fonciere\" column to numeric, forcing errors to NaN\n",
    "df_data[\"valeur_fonciere\"] = pd.to_numeric(df_data[\"valeur_fonciere\"], errors=\"coerce\")\n",
    "# Remove rows where \"valeur_fonciere\" is missing\n",
    "df_data = df_data.dropna(subset=[\"valeur_fonciere\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "225a23d537f78fbf",
   "metadata": {},
   "source": [
    "# Convert \"surface_reelle_bati\" column to numeric, forcing errors to NaN\n",
    "df_data[\"surface_reelle_bati\"] = pd.to_numeric(df_data[\"surface_reelle_bati\"], errors=\"coerce\")\n",
    "# Remove rows where \"surface_reelle_bati\" is missing\n",
    "df_data = df_data.dropna(subset=[\"surface_reelle_bati\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcb29ca28761f282",
   "metadata": {},
   "source": [
    "# Remove rows with more than 50% missing values\n",
    "df_data = df_data.dropna(thresh=len(df_data.columns) * 0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c53a15702f6e760",
   "metadata": {},
   "source": [
    "# Fill missing values in numerical columns with the median\n",
    "# Convert numerical columns to float type (forcing errors to NaN)\n",
    "cols_num = [\"surface_reelle_bati\", \"surface_terrain\", \"nombre_pieces_principales\", \"valeur_fonciere\"]\n",
    "for col in cols_num:\n",
    "    df_data[col] = pd.to_numeric(df_data[col], errors=\"coerce\")  # Convert to float\n",
    "    df_data[col] = df_data[col].fillna(df_data[col].median())  # Replace NaN with median"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0a4f50ce0fd55f1",
   "metadata": {},
   "source": [
    "# Fill missing values in categorical columns with \"Unknown\"\n",
    "cols_cat = [\"type_local\", \"nature_culture\"]\n",
    "for col in cols_cat:\n",
    "    df_data[col] = df_data[col].fillna(\"Unknown\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f88580bdf2021b5c",
   "metadata": {},
   "source": [
    "# Convert categorical variables into dummy/indicator variables (One-Hot Encoding)\n",
    "df_data = pd.get_dummies(df_data, columns=[\"type_local\", \"nature_culture\"], drop_first=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate the price per square meter for each property transaction\n",
    "df_data[\"prix_m2\"] = df_data[\"valeur_fonciere\"] / df_data[\"surface_reelle_bati\"]"
   ],
   "id": "940211bb6e9c53c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert the \"date_mutation\" column to a datetime format\n",
    "# \"errors='coerce'\" ensures that invalid dates are converted to NaT (Not a Time) instead of raising an error\n",
    "df_data[\"date_mutation\"] = pd.to_datetime(df_data[\"date_mutation\"], errors='coerce')\n",
    "\n",
    "# Extract the year of the transaction and store it in a new column \"annee_mutation\"\n",
    "# The \".dt.year\" extracts the year from the datetime column\n",
    "# \".astype(int)\" ensures that the values are stored as integers\n",
    "df_data[\"annee_mutation\"] = df_data[\"date_mutation\"].dt.year.astype(int)\n",
    "\n",
    "# Extract the month of the transaction and store it in a new column \"mois_mutation\"\n",
    "# The \".dt.month\" extracts the month from the datetime column\n",
    "# \".astype(int)\" ensures that the values are stored as integers\n",
    "df_data[\"mois_mutation\"] = df_data[\"date_mutation\"].dt.month.astype(int)\n"
   ],
   "id": "f51bc1d553bc246a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This code creates a new column 'annee_mois' that extracts the year and month\n",
    "# from the 'date_mutation' column as a period. It then groups the data by this\n",
    "# 'annee_mois' column and calculates the average property price ('valeur_fonciere')\n",
    "# for each month-year period, finally converting the 'annee_mois' values to string\n",
    "# format for easier display.\n",
    "df_data[\"annee_mois\"] = df_data[\"date_mutation\"].dt.to_period(\"M\")\n",
    "\n",
    "df_monthly = df_data.groupby(\"annee_mois\")[\"valeur_fonciere\"].mean().reset_index()\n",
    "df_monthly[\"annee_mois\"] = df_monthly[\"annee_mois\"].astype(str)"
   ],
   "id": "dcfaa45e1055ce8b"
  },
  {
   "cell_type": "code",
   "id": "9c6e126f3ba7ec28",
   "metadata": {},
   "source": [
    "# Display the first 10 rows after cleaning and transformation\n",
    "df_data.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a5d865f",
   "metadata": {},
   "source": [
    "# Convert 'code_postal' to string\n",
    "df_data[\"code_postal\"] = df_data[\"code_postal\"].astype(str)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71c0798c",
   "metadata": {},
   "source": [
    "# Deleting null values\n",
    "df_data = df_data[(df_data[\"surface_reelle_bati\"] > 0) & (df_data[\"valeur_fonciere\"] > 0)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36bd8a4ab9ddd504",
   "metadata": {},
   "source": [
    "# Display dataset information after cleaning and transformation\n",
    "df_data.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96f6519534c79731",
   "metadata": {},
   "source": [
    "# 3. Distribution of real estate prices"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2ccca48",
   "metadata": {},
   "source": [
    "# Distribution of real estate prices\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_data[df_data.valeur_fonciere <= 1e6].valeur_fonciere, bins=50, kde=True)\n",
    "plt.title(\"Distribution des valeurs foncières\")\n",
    "plt.xlabel(\"Prix (€)\")\n",
    "plt.ylabel(\"Nombre de transactions\")\n",
    "plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:,.0f}'))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52a6b065459dfb00",
   "metadata": {},
   "source": [
    "# 4. Visualization of real estate data by property type\n",
    "## 4.1. Relationship between built area and price by property type\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5cc61c8ec82fbf09",
   "metadata": {},
   "source": [
    "# Get unique property types\n",
    "unique_types = df_data.columns[df_data.columns.str.startswith(\"type_local_\")]\n",
    "\n",
    "# Create a separate chart for each property type\n",
    "for type_col in unique_types:\n",
    "    type_name = type_col.replace(\"type_local_\", \"\")  # Extract the property type name\n",
    "    subset = df_data[(df_data[type_col] == 1) & (df_data.surface_reelle_bati <= 4000) & (df_data.valeur_fonciere <= 1e6)]  # Filtrer les données\n",
    "\n",
    "    # Check if the subset contains data\n",
    "    if not subset.empty:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.scatterplot(x=subset.surface_reelle_bati, y=subset.valeur_fonciere)\n",
    "        plt.title(f\"Relation entre Surface Habitable et Prix pour {type_name}\")\n",
    "        plt.xlabel(\"Surface habitable (m²)\")\n",
    "        plt.ylabel(\"Prix (€)\")\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2. Distribution of property types in the dataset",
   "id": "554f8a75691b176f"
  },
  {
   "cell_type": "code",
   "id": "1c8838de837d9a57",
   "metadata": {},
   "source": [
    "# Distribution of property types\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Extract the names of property types\n",
    "type_local_columns = [col for col in df_data.columns if col.startswith(\"type_local_\")]\n",
    "\n",
    "# Count the number of occurrences for each property type\n",
    "type_counts = {col.replace(\"type_local_\", \"\"): df_data[col].sum() for col in type_local_columns}\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "df_type_counts = pd.DataFrame.from_dict(type_counts, orient=\"index\", columns=[\"count\"]).reset_index()\n",
    "df_type_counts.rename(columns={\"index\": \"type_local\"}, inplace=True)\n",
    "\n",
    "# Plot the chart\n",
    "sns.barplot(x=\"type_local\", y=\"count\", data=df_type_counts)\n",
    "plt.title(\"Répartition des types de biens\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Type de bien\")\n",
    "plt.ylabel(\"Nombre de transactions\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc130fa5",
   "metadata": {},
   "source": [
    "# 5. Data modeling\n",
    "## 5.1. Feature selection and decision tree model training"
   ]
  },
  {
   "cell_type": "code",
   "id": "024afcc2",
   "metadata": {},
   "source": [
    "# Features selection\n",
    "features = [\n",
    "    \"surface_reelle_bati\", \"surface_terrain\", \"nombre_pieces_principales\",\n",
    "    \"code_postal\", \"prix_m2\", \"annee_mutation\", \"mois_mutation\"\n",
    "] + [col for col in df_data.columns if col.startswith(\"type_local_\")]\n",
    "\n",
    "\n",
    "# Encode only the 'code_postal' column if necessary\n",
    "data_encoded = pd.get_dummies(df_data[features], columns=[\"code_postal\"], drop_first=True)\n",
    "\n",
    "X = data_encoded\n",
    "y = df_data[\"valeur_fonciere\"]\n",
    "\n",
    "# Split the data into training and test sets (80% / 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the decision tree\n",
    "tree_model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"Decision Tree - MAE : {mae_tree:.2f} € | R² : {r2_tree:.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.2. Random forest model training and evaluation",
   "id": "72464d0dffb645d3"
  },
  {
   "cell_type": "code",
   "id": "710fb7de",
   "metadata": {},
   "source": [
    "# Initialize and train the Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - MAE : {mae_rf:.2f} € | R² : {r2_rf:.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bddf8eb3",
   "metadata": {},
   "source": "# 6. Evaluating feature importance for real estate price prediction"
  },
  {
   "cell_type": "code",
   "id": "1c5a1c5e",
   "metadata": {},
   "source": [
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "# Convert into DataFrame\n",
    "df_importances = pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n",
    "\n",
    "# Group the values of postal codes and property types\n",
    "df_importances[\"Feature\"] = df_importances[\"Feature\"].replace({r\"code_postal_.*\": \"code_postal\", \n",
    "                                                                r\"type_local_.*\": \"type_local\"}, regex=True)\n",
    "\n",
    "# Average importance by grouped category\n",
    "df_grouped = df_importances.groupby(\"Feature\")[\"Importance\"].sum().reset_index()\n",
    "\n",
    "# Sort and display the results\n",
    "df_grouped = df_grouped.sort_values(by=\"Importance\", ascending=False)\n",
    "print(df_grouped)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb2b5716",
   "metadata": {},
   "source": [
    "# 7. Optimizing random forest model performance through hyperparameter tuning\n",
    "## 7.1 Hyperparameter search with grid search for random forest optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2be8d4a",
   "metadata": {},
   "source": [
    "# Define the grid of parameters to test\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200], \n",
    "    'max_depth': [10, 20], \n",
    "    'min_samples_split': [2, 5], \n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Start the search for the best parameters\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters :\", grid_search.best_params_)\n",
    "\n",
    "# Recalculate the model with the best parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "\n",
    "# New evaluation\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "print(f\"Optimized Random Forest - MAE : {mae_best:.2f} € | R² : {r2_best:.2f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7.2 Enhanced random forest model with best hyperparameters",
   "id": "bb7d7b4e93e4aa2c"
  },
  {
   "cell_type": "code",
   "id": "f690c91e",
   "metadata": {},
   "source": [
    "# Enhanced Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=200, max_depth=20, random_state=42, min_samples_split=2, min_samples_leaf=1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - MAE : {mae_rf:.2f} € | R² : {r2_rf:.2f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5f26c1bc",
   "metadata": {},
   "source": [
    "# 8. Analysis and visualization of real estate data\n",
    "## 8.1. Correlation matrix of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "08e31dd8",
   "metadata": {},
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr = df_data.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matrice de corrélation')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8.2. Relationship between built-up area and land value",
   "id": "4cc0b83953124b22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Relationship between built-up area and land value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_data['surface_reelle_bati'], y=df_data['valeur_fonciere'], alpha=0.5)\n",
    "plt.xscale('log')  # Échelle log pour mieux visualiser les tendances\n",
    "plt.yscale('log')\n",
    "plt.title('Relation entre surface bâtie et valeur foncière')\n",
    "plt.xlabel('Surface réelle bâtie (m²)')\n",
    "plt.ylabel('Valeur foncière (€)')\n",
    "plt.show()"
   ],
   "id": "23ba369f88efd163",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8.3. Average property price by postal code",
   "id": "cd2e9c4942dae1b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Average price by postal code\n",
    "plt.figure(figsize=(12, 6))\n",
    "code_postal_moy = df_data.groupby('code_postal')['valeur_fonciere'].mean().sort_values(ascending=False)[:20]\n",
    "sns.barplot(x=code_postal_moy.index, y=code_postal_moy.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Prix moyen de l'immobilier par code postal\")\n",
    "plt.xlabel('Code Postal')\n",
    "plt.ylabel('Prix moyen (€)')\n",
    "plt.show()"
   ],
   "id": "b6b3c936749464ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8.4. Yearly average property price trend",
   "id": "a166acbb072ea928"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This code generates a line plot showing the evolution of the average property price\n",
    "# over the years. It groups the data by year, calculates the mean price for each year,\n",
    "# and then visualizes the trend using a line plot with markers for each year.\n",
    "plt.figure(figsize=(10, 5))\n",
    "df_yearly = df_data.groupby(\"annee_mutation\")[\"valeur_fonciere\"].mean()\n",
    "sns.lineplot(x=df_yearly.index, y=df_yearly.values, marker=\"o\")\n",
    "plt.title(\"Evolution of the Average Property Price per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Price (€)\")\n",
    "plt.xticks(df_yearly.index.astype(int))\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "id": "89d531b31901bbea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8.5. Monthly average property price trend (by month and year)",
   "id": "dac07d5032333eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This code creates a line plot to visualize the average property price evolution\n",
    "# on a monthly and yearly basis. It groups the data by year-month, calculates\n",
    "# the mean property price for each period, and then displays the trend with markers\n",
    "# on the line plot, with properly rotated labels for better readability.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=\"annee_mois\", y=\"valeur_fonciere\", data=df_monthly, marker=\"o\")\n",
    "plt.title(\"Évolution du prix moyen des transactions immobilières (par mois et année)\")\n",
    "plt.xlabel(\"Mois et Année\")\n",
    "plt.ylabel(\"Prix moyen (€)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "5e43e843bf774a09",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
